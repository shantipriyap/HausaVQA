# HausaVQA

This repository contains baseline code for the Hausa Visual Question Answer (HausaVQA) dataset, which is the first dataset suitable for VQA and multimodal research in Hausa language. The NLP use cases applied to HaVQA dataset include:

* [Text-Only Machine Translation (T2T)](https://github.com/shantipriyap/HausaVQA/tree/main/T2T)
* [Multimodal Machine Translation (MMT)](https://github.com/shantipriyap/HausaVQA/tree/main/MMT)
* [Visual Question Elicitation (VQE)]()
* [Visual Question Answering (VQA)](https://github.com/shantipriyap/HausaVQA/tree/main/VQA)


## Contributors

* Shantipriya Parida, Silo AI, Helsinki, Finland
* Idris Abdulmumin, Ahmadu Bello University, Zaria, Nigeria
* Shamsuddeen Hassan Muhammad, University of Porto, Portugal
* Aneesh Bose, Microsoft, India
* Guneet Singh Kohli, GreyOrange, India
* Ibrahim Sa'id Ahmad, Bayero University, Kano, Nigeria 
* Ketan Kotwal, Idiap Research Institute, Switzerland
* Sayan Deb Sarkar, ETH Zurich, Switzerland
* Ond≈ôej Bojar, UFAL, Charles University, Prague, Czech Republic
* Habeebah Adamu Kakudi, Bayero University, Kano, Nigeria
